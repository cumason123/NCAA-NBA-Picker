{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN Player Point Prediction",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cumason123/NCAA-NBA-Picker/blob/master/RNN_Player_Point_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_jPgFx3Klxbb",
        "colab_type": "code",
        "outputId": "28c8b73e-5c83-452a-a02e-4623b7aa2310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#tf.enable_eager_execution()\n",
        "\n",
        "!gsutil cp gs://stardust-hackathon/ncaa-mbb/player_box.csv /tmp/\n",
        "\n",
        "df = pd.read_csv(\"/tmp/player_box.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authenticated\n",
            "Copying gs://stardust-hackathon/ncaa-mbb/player_box.csv...\n",
            "- [1 files][ 71.6 MiB/ 71.6 MiB]                                                \n",
            "Operation completed over 1 objects/71.6 MiB.                                     \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FTZnWFae5eO4",
        "colab_type": "code",
        "outputId": "72e6e47b-ab2b-4f36-cc98-e74a89e0333f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "cell_type": "code",
      "source": [
        "print(df.head(10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   team_code  season             game_id   game_date  player_id jersey_num  \\\n",
            "0      768.0    2018    327-768-2019-1-9  2019-01-09  2082634.0          1   \n",
            "1      768.0    2018   698-768-2019-1-15  2019-01-15  2082634.0          1   \n",
            "2      768.0    2018  768-606-2018-11-18  2018-11-18  2082634.0          1   \n",
            "3      768.0    2018  768-352-2018-12-30  2018-12-30  2082634.0          1   \n",
            "4      768.0    2018   768-521-2019-1-12  2019-01-12  2082634.0          1   \n",
            "5      768.0    2018    768-51-2019-1-21  2019-01-21  2082634.0          1   \n",
            "6      768.0    2018  768-315-2018-12-22  2018-12-22  2082634.0          1   \n",
            "7      768.0    2018    703-768-2019-1-5  2019-01-05  2082634.0          1   \n",
            "8      768.0    2018   768-328-2019-1-19  2019-01-19  2082634.0          1   \n",
            "9      768.0    2018    768-700-2019-1-2  2019-01-02  2082634.0          1   \n",
            "\n",
            "    pts   fga  fga3  fgm     ...       ast  blk  stl  dreb  oreb   reb   pf  \\\n",
            "0  17.0  14.0   0.0  7.0     ...       0.0  1.0  0.0   5.0   7.0  12.0  1.0   \n",
            "1   8.0   4.0   0.0  3.0     ...       2.0  0.0  0.0   3.0   1.0   4.0  3.0   \n",
            "2   0.0   0.0   0.0  0.0     ...       0.0  0.0  0.0   0.0   0.0   0.0  0.0   \n",
            "3  11.0   6.0   0.0  4.0     ...       1.0  1.0  0.0   5.0   6.0  11.0  2.0   \n",
            "4  15.0   8.0   0.0  5.0     ...       1.0  2.0  1.0  11.0   4.0  15.0  3.0   \n",
            "5   3.0   8.0   0.0  1.0     ...       0.0  0.0  0.0   7.0   1.0   8.0  4.0   \n",
            "6   4.0   4.0   0.0  2.0     ...       0.0  1.0  0.0   0.0   1.0   1.0  3.0   \n",
            "7  17.0  12.0   0.0  8.0     ...       1.0  0.0  0.0   4.0   5.0   9.0  3.0   \n",
            "8  11.0  10.0   0.0  4.0     ...       3.0  1.0  1.0   5.0   2.0   7.0  4.0   \n",
            "9  12.0   4.0   0.0  3.0     ...       2.0  0.0  0.0   7.0   1.0   8.0  2.0   \n",
            "\n",
            "    tf  tov  mins_played  \n",
            "0  0.0  1.0         34.0  \n",
            "1  0.0  0.0         22.0  \n",
            "2  0.0  0.0          0.0  \n",
            "3  0.0  1.0         19.0  \n",
            "4  0.0  1.0         27.0  \n",
            "5  0.0  1.0         24.0  \n",
            "6  0.0  1.0         10.0  \n",
            "7  0.0  1.0         22.0  \n",
            "8  0.0  3.0         27.0  \n",
            "9  0.0  2.0         28.0  \n",
            "\n",
            "[10 rows x 23 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6B3i569i_pf2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "player = df[df['player_id'] == 2082634.0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CrYiSMgoB6C2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "player_info = player.loc[:, 'pts':'mins_played':1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lQo60sKIZPps",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = player_info[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJA53bQFZ62f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = player_info.loc[:, 'pts'][:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OtxOenpndLg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = x.iloc[::-1]\n",
        "y = y.iloc[::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kjOsajagaQa2",
        "colab_type": "code",
        "outputId": "cb6f7b7e-dfce-4cc4-ffd7-8c9a0044339b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "xtensor = tf.convert_to_tensor(x.values, dtype = tf.float32)\n",
        "ytensor = tf.convert_to_tensor(y.values, dtype = tf.float32)\n",
        "\n",
        "xtensor = tf.reshape(xtensor, (9, 1, 17))\n",
        "ytensor = tf.reshape(ytensor, (9, 1, 1))\n",
        "\n",
        "xtensor = tf.math.l2_normalize(\n",
        "    xtensor,\n",
        "    axis=(0,1)\n",
        ")\n",
        "ytensor = tf.math.l2_normalize(\n",
        "    ytensor,\n",
        "    axis=(0,1)\n",
        ")\n",
        "\n",
        "\n",
        "print(xtensor.shape, ytensor.shape)\n",
        "print(xtensor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9, 1, 17) (9, 1, 1)\n",
            "Tensor(\"l2_normalize:0\", shape=(9, 1, 17), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JMVBB8fXgXZI",
        "colab_type": "code",
        "outputId": "b0cc3d7d-3622-4bb1-cb3f-087c9c45c102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reshape(y[0], (1,1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Reshape_2:0' shape=(1, 1) dtype=float64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "xcX96EJ7FQ6K",
        "colab_type": "code",
        "outputId": "1a5c8229-9396-4c73-8ac9-dbbf01ae0e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "lstm = tf.contrib.rnn.BasicLSTMCell(17)\n",
        "\n",
        "initial_state = state = lstm.zero_state(1, dtype=tf.float32)\n",
        "\n",
        "dense1 = tf.layers.Dense(units = 1)\n",
        "\n",
        "loss = 0\n",
        "for i in range(9):\n",
        "    output, state = lstm(xtensor[i], state)\n",
        "    logits = dense1(output)\n",
        "    \n",
        "    loss += tf.nn.sigmoid_cross_entropy_with_logits(labels=ytensor[i], logits=logits)    \n",
        "\n",
        "final_state = state\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-d6f67686f11d>:1: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
            "Tensor(\"add_8:0\", shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UAz7Ws6YFtcA",
        "colab_type": "code",
        "outputId": "bfc698e6-af0a-4312-c6f2-2da076753fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "\n",
        "\n",
        "'''\n",
        "To classify images using a recurrent neural network, we consider every image\n",
        "row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n",
        "handle 28 sequences of 28 steps for every sample.\n",
        "'''\n",
        "\n",
        "# Training Parameters\n",
        "learning_rate = 0.001\n",
        "training_steps = 10000\n",
        "batch_size = 1\n",
        "display_step = 200\n",
        "\n",
        "# Network Parameters\n",
        "num_input = 17\n",
        "timesteps = 9 # timesteps\n",
        "num_hidden = 128 # hidden layer num of features\n",
        "num_scores = 1 \n",
        "\n",
        "# tf Graph input\n",
        "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
        "Y = tf.placeholder(\"float\", [None, num_scores])\n",
        "\n",
        "# Define weights\n",
        "weights = {\n",
        "    'out': tf.Variable(tf.random_normal([num_hidden, num_scores]))\n",
        "}\n",
        "biases = {\n",
        "    'out': tf.Variable(tf.random_normal([num_scores]))\n",
        "}\n",
        "\n",
        "\n",
        "def RNN(x, weights, biases):\n",
        "\n",
        "    # Prepare data shape to match `rnn` function requirements\n",
        "    # Current data input shape: (batch_size, timesteps, n_input)\n",
        "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
        "\n",
        "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
        "    x = tf.unstack(x, timesteps, 1)\n",
        "\n",
        "    # Define a lstm cell with tensorflow\n",
        "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
        "\n",
        "    # Get lstm cell output\n",
        "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
        "\n",
        "    # Linear activation, using rnn inner loop last output\n",
        "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
        "\n",
        "logits = RNN(X, weights, biases)\n",
        "prediction = tf.nn.sigmoid(logits)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "    logits=logits, labels=Y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Evaluate model (with test logits, for dropout to be disabled)\n",
        "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "\n",
        "# Start training\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "\n",
        "    for step in range(1, training_steps+1):\n",
        "        batch_x, batch_y = (x.values,y.values)  ######mnist.train.next_batch(batch_size)\n",
        "        # Reshape data to get 28 seq of 28 elements\n",
        "        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
        "        batch_y = batch_y.reshape((timesteps, num_scores))\n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
        "                                                                 Y: batch_y})\n",
        "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
        "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(acc))\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "\n",
        "    # Calculate accuracy for 128 mnist test images\n",
        "    test_len = 1\n",
        "    test_data = x.values.reshape(1,9,17)\n",
        "    test_label = y.values.reshape(9,1)\n",
        "    print(\"Testing Accuracy:\", \\\n",
        "        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1, Minibatch Loss= -228.8556, Training Accuracy= 1.000\n",
            "Step 200, Minibatch Loss= -2235.3918, Training Accuracy= 1.000\n",
            "Step 400, Minibatch Loss= -3865.2004, Training Accuracy= 1.000\n",
            "Step 600, Minibatch Loss= -5516.9746, Training Accuracy= 1.000\n",
            "Step 800, Minibatch Loss= -7200.4829, Training Accuracy= 1.000\n",
            "Step 1000, Minibatch Loss= -8884.0547, Training Accuracy= 1.000\n",
            "Step 1200, Minibatch Loss= -10567.6270, Training Accuracy= 1.000\n",
            "Step 1400, Minibatch Loss= -12251.1836, Training Accuracy= 1.000\n",
            "Step 1600, Minibatch Loss= -13934.7354, Training Accuracy= 1.000\n",
            "Step 1800, Minibatch Loss= -15618.2988, Training Accuracy= 1.000\n",
            "Step 2000, Minibatch Loss= -17301.9844, Training Accuracy= 1.000\n",
            "Step 2200, Minibatch Loss= -18985.7012, Training Accuracy= 1.000\n",
            "Step 2400, Minibatch Loss= -20669.4141, Training Accuracy= 1.000\n",
            "Step 2600, Minibatch Loss= -22353.1250, Training Accuracy= 1.000\n",
            "Step 2800, Minibatch Loss= -24036.8359, Training Accuracy= 1.000\n",
            "Step 3000, Minibatch Loss= -25720.5527, Training Accuracy= 1.000\n",
            "Step 3200, Minibatch Loss= -27404.2598, Training Accuracy= 1.000\n",
            "Step 3400, Minibatch Loss= -29087.9707, Training Accuracy= 1.000\n",
            "Step 3600, Minibatch Loss= -30771.6797, Training Accuracy= 1.000\n",
            "Step 3800, Minibatch Loss= -32455.3887, Training Accuracy= 1.000\n",
            "Step 4000, Minibatch Loss= -34139.0938, Training Accuracy= 1.000\n",
            "Step 4200, Minibatch Loss= -35822.8047, Training Accuracy= 1.000\n",
            "Step 4400, Minibatch Loss= -37506.5156, Training Accuracy= 1.000\n",
            "Step 4600, Minibatch Loss= -39190.2227, Training Accuracy= 1.000\n",
            "Step 4800, Minibatch Loss= -40873.9219, Training Accuracy= 1.000\n",
            "Step 5000, Minibatch Loss= -42557.6328, Training Accuracy= 1.000\n",
            "Step 5200, Minibatch Loss= -44241.3281, Training Accuracy= 1.000\n",
            "Step 5400, Minibatch Loss= -45925.0391, Training Accuracy= 1.000\n",
            "Step 5600, Minibatch Loss= -47608.7500, Training Accuracy= 1.000\n",
            "Step 5800, Minibatch Loss= -49292.4531, Training Accuracy= 1.000\n",
            "Step 6000, Minibatch Loss= -50976.1602, Training Accuracy= 1.000\n",
            "Step 6200, Minibatch Loss= -52659.8633, Training Accuracy= 1.000\n",
            "Step 6400, Minibatch Loss= -54343.5742, Training Accuracy= 1.000\n",
            "Step 6600, Minibatch Loss= -56027.2695, Training Accuracy= 1.000\n",
            "Step 6800, Minibatch Loss= -57710.9727, Training Accuracy= 1.000\n",
            "Step 7000, Minibatch Loss= -59394.6797, Training Accuracy= 1.000\n",
            "Step 7200, Minibatch Loss= -61078.3750, Training Accuracy= 1.000\n",
            "Step 7400, Minibatch Loss= -62761.9844, Training Accuracy= 1.000\n",
            "Step 7600, Minibatch Loss= -64445.0820, Training Accuracy= 1.000\n",
            "Step 7800, Minibatch Loss= -66128.0703, Training Accuracy= 1.000\n",
            "Step 8000, Minibatch Loss= -67811.0312, Training Accuracy= 1.000\n",
            "Step 8200, Minibatch Loss= -69493.9922, Training Accuracy= 1.000\n",
            "Step 8400, Minibatch Loss= -71176.9453, Training Accuracy= 1.000\n",
            "Step 8600, Minibatch Loss= -72859.9062, Training Accuracy= 1.000\n",
            "Step 8800, Minibatch Loss= -74542.8516, Training Accuracy= 1.000\n",
            "Step 9000, Minibatch Loss= -76225.8047, Training Accuracy= 1.000\n",
            "Step 9200, Minibatch Loss= -77908.7656, Training Accuracy= 1.000\n",
            "Step 9400, Minibatch Loss= -79591.7266, Training Accuracy= 1.000\n",
            "Step 9600, Minibatch Loss= -81274.6641, Training Accuracy= 1.000\n",
            "Step 9800, Minibatch Loss= -82957.6250, Training Accuracy= 1.000\n",
            "Step 10000, Minibatch Loss= -84640.5781, Training Accuracy= 1.000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kcvg1eZBmPNn",
        "colab_type": "code",
        "outputId": "78bebdac-b303-4c14-e9b6-25f4ce27ded7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "ytest = list(player_info.loc[:, 'pts'][:-1])\n",
        "#print(ytest)\n",
        "s = 0\n",
        "alpha = 0.7\n",
        "average = 0\n",
        "for i in range(0,9-1):\n",
        "    s = alpha * s + (1-alpha) * ytest[i]\n",
        "    average += abs(s - ytest[i+1])/(max(ytest[i+1], s))\n",
        "average /= 9\n",
        "print('exponential average estimation accuracy')\n",
        "print(average)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exponential average estimation accuracy\n",
            "0.4940318001683852\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}